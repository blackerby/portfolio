---
title: Philosophy
bookToc: false
---

# A Reflective Essay on Information, Technology, Humanity, and Purpose

I distinctly remember what first piqued my interest in computing and technology. I was in sixth or seventh grade, spending the night at a friend's house, and before settling in for a late night and early morning of action movie after action movie followed by far too little sleep, we sat at the desktop computer in the basement guestroom. Instead of playing through one of his favorite science fiction flight simulator games, my friend showed me how some text surrounded by angle brackets he typed out in NotePad could turn into a website anyone anywhere in the world could visit thanks to AngelFire. HTML: HyperText Markup Language. _Language._ I knew language. I loved language! French and English were my two favorite classes in school at the time. All it took to get a computer to do what you wanted was to learn its language? I could do that. I was hooked.

In the almost 25 years since that night, that interest in the intersection of language and technology has gone through ups and downs, wavering but never flickering out. I shudder to think how much money I've spent on programming language books and courses that I never finished -- Java, PHP, Ruby, Python, Perl, C, Haskell, OCaml, Standard ML, Scheme, Racket, Common Lisp, JavaScript, Clojure, Elm, Go, Smalltalk, Prolog, R, and others I'm sure I'm forgetting. Once I realized how much math figured into this field, something I unfortunately decided I wasn't good at a young age because I wasn't as fast at it as my peers (and in which I tried to justify or feign disinterest as I announced that it wasn't necessary for what I wanted to do), I more or less gave up, again and again, immersing myself in and identifying with the more human side of my interest in language, ultimately earning a bachelor's degree in classical languages with an emphasis on Ancient Greek.

I think what ties these scattershot interests together is an interest in structure, form, and, most importantly, meaning. What motivates me now, I think, is learning how to use these interests to help people, which has been the focus of my career up to this point. Each job I have held since college, from working as a community organizer in inner-city Birmingham, serving as a youth minister at an Episcopal church in Huntsville, and now teaching Latin at a private school in suburban Birmingham, has involved navigating, organizing, and interpreting information. In each position, there have been situations in which I have asked or been asked to answer questions that should be easy to answer, but haven't been because of a lack of underlying form, structure, or organization to the information available to help answer the question. In other words, a lack of meaning, or semantic context. So my goal is this: to develop interpersonal and technical skills that will help human-serving organizations confidently manage the information at their disposal.

My understanding of information is becoming grounded in Buckland's conceptualization of information as thing, because as Buckland says, "expert systems and information retrieval systems" -- in other words, technological systems for working with information -- "can only deal with information in the sense of information as thing" (352). Human-serving organizations abound with instances of information as thing: policy documents, meeting minutes, emails, blog posts, newsletters, bills, receipts, spreadsheets, invoices, and more. I believe that technology has a role to play in managing these informative objects but that in many cases, the necessary skills are lacking from these organizations. I want to be someone who can bring such skills to the table for these human-serving organizations, all while being careful to avoid implementing technology for technology's sake and instead recalling Ma's dictum that

> The design of information systems and the education of information professionals depend upon a sound theory of communication, one that describes and explains how humans really interact with each other and how meanings are constructed through acts of understanding. (718-719)

In other words: the answer to the question "What is the purpose of all of this?" is understanding and collaborative meaning construction.

As an aspiring information professional and technologist, I hope to carry the message of Zobel's work on information retrieval (IR) into my practice. What so impressed me about the paper of his that we read this semester is that purpose is at the center of his conceptualization of IR. I found the following definition of IR from his paper inspiring: "the study of techniques for supporting human cognition with documents, using material that is sourced from large document collections" (25).

"Supporting human cognition." Not replacing, but supporting. In other words, being mindful of who and what this work is for. Does artificial intelligence have a role to play in any of this? If so, what do we mean by artificial intelligence, and what is that role?

One place to start as we attempt to answer these questions is with the work of Alan Turing, the mathematician and computer scientist whom we have to thank (or perhaps from some perspectives, to blame) for computing as we know it today. This essay is not an appropriate venue for a thorough discussion of Turing's work, nor am I anywhere near expert enough in it to make any claims except for this: that we cannot separate the history of computing from the history of artificial intelligence. For more on this idea, Sebastian Sunday Grève's recent essay for _Aeon_ is a good place to start.

We should also acknowledge that there is an undeniably darker, and in some cases sinister, side to artificial intelligence as well. Introducing a series of articles on "AI colonialism" for the _MIT Technology Review_, Karen Hao writes "The more users a company can acquire for its products, the more subjects it can have for its algorithms, and the more resources—data—it can harvest from their activities, their movements, and even their bodies." To what end? Writing for _Politico_'s Digital Future Daily newsletter, Derek Robertson synthesizes a Twitter thread in which Emily Bender, a computational linguist at the University of Washington, criticizes Eric Jang's essay in which he lays out his "ambitions to build an artificial general intelligence that would encapsulate the entirety of human experience." Robertson says the thread criticizing the essay is

> a useful case study in two different technological visions of the world: One where progress is inevitable, competition is zero-sum, and engineers should be single-mindedly focused on getting there first, and one where technological advancement is more holistic and human-centered.

Just how far does the former of these two visions go? In an essay for _Current Affairs_, Phil Torres investigates a philosophy called longtermism, "the idea that what *matters most* is for “Earth-originating intelligent life” to fulfill its *potential* in the cosmos." Though it may seem initially unrelated to AI, Torres says that "many longtermists believe that superintelligent machines pose the greatest single hazard to human survival, but they seem convinced that if humanity were to create a “friendly” superintelligence whose goals are properly “aligned” with our “human goals,” then a new Utopian age of unprecedented security and flourishing would suddenly commence."

The latter, and much less extreme vision, is illustrated on the about page of Timnit Gebru's DAIR, the Distributed AI Research Institute, "an interdisciplinary and globally distributed AI research institute rooted in the belief that AI is not inevitable, its harms are preventable, and when its production and deployment include diverse perspectives and deliberate processes it can be beneficial."

This is the vision we should strive for, the vision that is in line with Ma's and Zobel's views, and the vision that I would want to be a part of. Information is for people, all people, and technology that does not recognize and advance that point of view can be harmful and dangerous. I am grateful to be taking my first steps into LIS, a field which, though technologically informed, places people's needs first.

References:

Buckland, M. K. (1991). Information as thing. Journal of the American Society for Information Science, 42 (5), 351-360.

DAIR. "About." https://www.dair-institute.org/about. Accessed May 1, 2022.

Grève, Sebastian S. "AI’s first philosopher." https://aeon.co/essays/why-we-should-remember-alan-turing-as-a-philosopher. Accessed May 1, 2022.

Hao, Karen. "Artificial intelligence is creating a new colonial world order." https://www.technologyreview.com/2022/04/19/1049592/artificial-intelligence-colonialism/. Accessed May 1, 2022.

Ma, L. (2012). Meanings of information: The assumptions and research consequences of three foundational LIS theories. Journal of the
American Society for Information Science, 63 (4), 716-723.

Robertson, Derek. https://www.politico.com/newsletters/digital-future-daily/2022/04/29/cryptos-strange-new-respectability-00029062. Accessed May 1, 2022.

Zobel, J., (2017). What we talk about when we talk about information retrieval. ACM SIGIR Forum, 51 (3), 18-26.
